{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoSDF evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trimesh\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from typing import List, Dict\n",
    "\n",
    "# Define input and output directories\n",
    "input_folder = r\"/home/student/Documents/Data/meshes_data/synthetisch_meshes_v3\"\n",
    "results_folder = r\"/home/student/Documents/Data/AutoSDF_results/AutoSDF_results_0\"\n",
    "output_csv = r\"/home/student/Documents/Data/Evaluation_results/evaluatie.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berekeningen\n",
    "def calculate_iou(mesh1: trimesh.Trimesh, mesh2: trimesh.Trimesh) -> float:\n",
    "    try:\n",
    "        intersection = mesh1.intersection(mesh2)\n",
    "        union = mesh1.union(mesh2)\n",
    "        return intersection.volume / union.volume if union.volume > 0 else 0\n",
    "    except Exception:\n",
    "        return -1\n",
    "\n",
    "def chamfer_distance(mesh1: trimesh.Trimesh, mesh2: trimesh.Trimesh, num_samples: int = 10000) -> float:\n",
    "    points1 = mesh1.sample(num_samples)\n",
    "    points2 = mesh2.sample(num_samples)\n",
    "    \n",
    "    distances1 = pairwise_distances(points1, points2)\n",
    "    distances2 = pairwise_distances(points2, points1)\n",
    "    \n",
    "    chamfer_dist1 = np.mean(np.min(distances1, axis=1))\n",
    "    chamfer_dist2 = np.mean(np.min(distances2, axis=1))\n",
    "    \n",
    "    return chamfer_dist1 + chamfer_dist2\n",
    "\n",
    "def normal_consistency(mesh1: trimesh.Trimesh, mesh2: trimesh.Trimesh, num_samples: int = 10000) -> float:\n",
    "    points1, face_indices1 = mesh1.sample(num_samples, return_index=True)\n",
    "    points2, face_indices2 = mesh2.sample(num_samples, return_index=True)\n",
    "\n",
    "    normals1 = mesh1.face_normals[face_indices1]\n",
    "    normals2 = mesh2.face_normals[face_indices2]\n",
    "\n",
    "    dot_products = np.einsum('ij,ij->i', normals1, normals2)\n",
    "    \n",
    "    dot_products = np.clip(dot_products, -1.0, 1.0)\n",
    "\n",
    "    return np.mean(np.abs(dot_products))\n",
    "\n",
    "def f_score(mesh1: trimesh.Trimesh, mesh2: trimesh.Trimesh, threshold: float = 0.01, num_samples: int = 10000) -> float:\n",
    "    points1 = mesh1.sample(num_samples)\n",
    "    points2 = mesh2.sample(num_samples)\n",
    "\n",
    "    dists1 = pairwise_distances(points1, points2)\n",
    "    min_dists1 = np.min(dists1, axis=1)\n",
    "    \n",
    "    dists2 = pairwise_distances(points2, points1)\n",
    "    min_dists2 = np.min(dists2, axis=1)\n",
    "\n",
    "    precision = np.mean(min_dists1 < threshold)\n",
    "\n",
    "    recall = np.mean(min_dists2 < threshold)\n",
    "\n",
    "    if precision + recall == 0:\n",
    "        return 0.0\n",
    "    return 2 * (precision * recall) / (precision + recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gt.obj', '', '1.obj', -1, 0.05696947254018829, 0.4063489246364379, 0.33940857269111796, 0.3314]\n",
      "['gt.obj', '', '0.obj', -1, 0.06243365843712444, 0.4069297797415197, 0.2727707531610775, 0.2604]\n",
      "['gt.obj', '', '2.obj', -1, 0.06113887600195643, 0.40827958552108956, 0.30758280234070223, 0.2904]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "11 columns passed, passed data had 8 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/miniconda3/envs/autosdf/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_or_indexify_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    899\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/autosdf/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_validate_or_indexify_columns\u001b[0;34m(content, columns)\u001b[0m\n\u001b[1;32m    945\u001b[0m             \u001b[0;31m# caller's responsibility to check for this...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m             raise AssertionError(\n\u001b[0m\u001b[1;32m    947\u001b[0m                 \u001b[0;34mf\"{len(columns)} columns passed, passed data had \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 11 columns passed, passed data had 8 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_708463/2527785647.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m# Execute the mesh processing function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m \u001b[0mprocess_meshes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_csv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_708463/2527785647.py\u001b[0m in \u001b[0;36mprocess_meshes\u001b[0;34m(input_folder, results_folder, output_csv)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mcolumn_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34mf\"Level {i+1}\"\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_depth\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Result Folder'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Result File'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'IoU'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Chamfer Distance'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Normal Consistancy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'f-score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Coverance'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcolumn_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_csv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Results saved to {output_csv}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/autosdf/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    692\u001b[0m                         \u001b[0;31m# ndarray], Index, Series], Sequence[Any]]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    693\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 694\u001b[0;31m                     arrays, columns, index = nested_data_to_arrays(\n\u001b[0m\u001b[1;32m    695\u001b[0m                         \u001b[0;31m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m                         \u001b[0;31m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/autosdf/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mnested_data_to_arrays\u001b[0;34m(data, columns, index, dtype)\u001b[0m\n\u001b[1;32m    481\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 483\u001b[0;31m     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    484\u001b[0m     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/autosdf/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, dtype)\u001b[0m\n\u001b[1;32m    797\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m     \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_finalize_columns_and_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/autosdf/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_finalize_columns_and_data\u001b[0;34m(content, columns, dtype)\u001b[0m\n\u001b[1;32m    899\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m         \u001b[0;31m# GH#26429 do not raise user-facing AssertionError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 901\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcontents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 11 columns passed, passed data had 8 columns"
     ]
    }
   ],
   "source": [
    "# creatie csv\n",
    "def split_path(path: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Split a file path into its folder hierarchy components.\n",
    "    \n",
    "    Parameters:\n",
    "        path (str): File path to split.\n",
    "    \n",
    "    Returns:\n",
    "        List[str]: List of folder components.\n",
    "    \"\"\"\n",
    "    return path.split(os.sep)\n",
    "\n",
    "def process_meshes(input_folder: str, results_folder: str, output_csv: str) -> None:\n",
    "    \"\"\"\n",
    "    Process all 3D meshes from the input and results folders to compute IoU and Chamfer Distance.\n",
    "    \n",
    "    Parameters:\n",
    "        input_folder (str): Directory containing the original meshes.\n",
    "        results_folder (str): Directory containing processed meshes.\n",
    "        output_csv (str): Output CSV file to save comparison results.\n",
    "    \"\"\"\n",
    "    results: List[List[str, str, float, float, float, float, float]] = []\n",
    "    input_meshes: Dict[str, str] = {}\n",
    "    \n",
    "    for root, _, files in os.walk(input_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\"gt.obj\"):\n",
    "                rel_path = os.path.relpath(os.path.join(root, file), input_folder)\n",
    "                input_meshes[rel_path] = os.path.join(root, file)\n",
    "    \n",
    "    for rel_path, input_path in input_meshes.items():\n",
    "        result_subfolder = os.path.join(results_folder, os.path.dirname(rel_path))\n",
    "        if os.path.exists(result_subfolder):\n",
    "            for result_root, _, result_files in os.walk(result_subfolder):\n",
    "                for result_file in result_files:\n",
    "                    if result_file.endswith(\".obj\"):\n",
    "                        result_path: str = os.path.join(result_root, result_file)\n",
    "                        mesh1 = trimesh.load_mesh(input_path)\n",
    "                        mesh2 = trimesh.load_mesh(result_path)\n",
    "                        \n",
    "                        iou = calculate_iou(mesh1, mesh2)\n",
    "                        chamfer_dist = chamfer_distance(mesh1, mesh2)\n",
    "                        normal_cons = normal_consistency(mesh1, mesh2)\n",
    "                        f = f_score(mesh1, mesh2)\n",
    "                        \n",
    "                        rel_result_path = os.path.relpath(result_path, results_folder)\n",
    "                        input_hierarchy = split_path(rel_path)\n",
    "                        result_folder = os.path.basename(os.path.dirname(rel_result_path))\n",
    "                        result_filename = os.path.basename(rel_result_path)\n",
    "                        \n",
    "                        results.append(input_hierarchy + [result_folder, result_filename, iou, chamfer_dist, normal_cons, f])\n",
    "                        print(results[-1])\n",
    "    \n",
    "    max_depth = max(len(row) for row in results)\n",
    "    column_names = [f\"Level {i+1}\" for i in range(max_depth - 4)] + ['Result Folder', 'Result File', 'IoU', 'Chamfer Distance', 'Normal Consistancy', 'f-score']\n",
    "    \n",
    "    df = pd.DataFrame(results, columns=column_names)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Results saved to {output_csv}\")\n",
    "\n",
    "# Execute the mesh processing function\n",
    "process_meshes(input_folder, results_folder, output_csv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resulaten niet volledig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import trimesh\n",
    "import pandas as pd\n",
    "from typing import List, Dict\n",
    "import numpy as np\n",
    "\n",
    "def process_meshes(input_folder: str, results_folder: str, output_csv: str) -> None:\n",
    "    \"\"\"\n",
    "    Verwerkt alle 3D meshes en vergelijkt ze met resultaten indien beschikbaar.\n",
    "    Als er geen resultaten zijn, wordt dit vermeld in de CSV.\n",
    "    \n",
    "    Parameters:\n",
    "        input_folder (str): Map met originele (ground truth) meshes.\n",
    "        results_folder (str): Map met de gegenereerde meshes.\n",
    "        output_csv (str): Output CSV-bestand waarin de resultaten worden opgeslagen.\n",
    "    \"\"\"\n",
    "    results: List[List[str]] = []\n",
    "    input_meshes: Dict[str, str] = {}\n",
    "\n",
    "    # Verzamel alle input meshes\n",
    "    for root, _, files in os.walk(input_folder):\n",
    "        for file in files:\n",
    "            if file.endswith(\"gt.obj\"):\n",
    "                rel_path = os.path.relpath(os.path.join(root, file), input_folder)\n",
    "                input_meshes[rel_path] = os.path.join(root, file)\n",
    "\n",
    "    for rel_path, input_path in input_meshes.items():\n",
    "        result_subfolder = os.path.join(results_folder, os.path.dirname(rel_path))\n",
    "        found_result = False  # Nieuw: bijhouden of er resultaat is gevonden\n",
    "\n",
    "        if os.path.exists(result_subfolder):\n",
    "            for result_root, _, result_files in os.walk(result_subfolder):\n",
    "                for result_file in result_files:\n",
    "                    if result_file.endswith(\".obj\"):\n",
    "                        found_result = True  # Er is een resultaatbestand gevonden\n",
    "                        result_path: str = os.path.join(result_root, result_file)\n",
    "\n",
    "                        mesh1 = trimesh.load_mesh(input_path)\n",
    "                        mesh2 = trimesh.load_mesh(result_path)\n",
    "\n",
    "                        iou = calculate_iou(mesh1, mesh2)\n",
    "                        chamfer_dist = chamfer_distance(mesh1, mesh2)\n",
    "                        normal_cons = normal_consistency(mesh1, mesh2)\n",
    "                        f = f_score(mesh1, mesh2)\n",
    "\n",
    "                        rel_result_path = os.path.relpath(result_path, results_folder)\n",
    "                        input_hierarchy = split_path(rel_path)\n",
    "                        result_folder = os.path.basename(os.path.dirname(rel_result_path))\n",
    "                        result_filename = os.path.basename(rel_result_path)\n",
    "\n",
    "                        results.append(input_hierarchy + [result_folder, result_filename, iou, chamfer_dist, normal_cons, f])\n",
    "                        print(results[-1])\n",
    "        \n",
    "        # Als geen enkel resultaatbestand is gevonden\n",
    "        if not found_result:\n",
    "            input_hierarchy = split_path(rel_path)\n",
    "            results.append(input_hierarchy + [\"geen results\", \"\", None, None, None, None])\n",
    "            print(results[-1])\n",
    "\n",
    "    # Kolomnamen genereren afhankelijk van de inputstructuur\n",
    "    max_depth = max(len(row) for row in results)\n",
    "    column_names = [f\"Level {i+1}\" for i in range(max_depth - 4)] + ['Result Folder', 'Result File', 'IoU', 'Chamfer Distance', 'Normal Consistancy', 'f-score']\n",
    "\n",
    "    df = pd.DataFrame(results, columns=column_names)\n",
    "    df.to_csv(output_csv, index=False)\n",
    "    print(f\"Resultaten opgeslagen in: {output_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autosdf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
